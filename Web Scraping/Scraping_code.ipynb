{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db69d18a",
   "metadata": {},
   "source": [
    "# This code is for one page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5578ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data scraped and saved to taqat_talents.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the page\n",
    "url = \"https://taqat-gaza.com/public/en/talents\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Step 2: Parse HTML\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Step 3: Find all talent cards\n",
    "talents = soup.find_all(\"div\", class_=\"card\")  # You may adjust if needed\n",
    "\n",
    "# Step 4: Extract info\n",
    "data = []\n",
    "for card in talents:\n",
    "    name = card.find(\"h5\", class_=\"mb-0\")\n",
    "    specialty = card.find(\"span\", class_=\"text-muted d-block mb-2\")\n",
    "    \n",
    "    # Extracting experience and project count\n",
    "    experience = \"\"\n",
    "    projects = \"\"\n",
    "\n",
    "    # Find all stat containers\n",
    "    stats_blocks = card.find_all(\"div\", class_=\"stats m-1\")\n",
    "    for stat in stats_blocks:\n",
    "        label = stat.find(\"p\")\n",
    "        value = stat.find(\"span\")\n",
    "        if label and value:\n",
    "            label_text = label.get_text(strip=True).lower()\n",
    "            if \"projects\" in label_text:\n",
    "                projects = value.get_text(strip=True)\n",
    "            elif \"experience\" in label_text:\n",
    "                experience = value.get_text(strip=True)\n",
    "    \n",
    "            \n",
    "\n",
    "    data.append({\n",
    "        \"Name\": name.text.strip() if name else \"\",\n",
    "        \"Specialty\": specialty.text.strip() if specialty else \"\",\n",
    "        \"Experience (years)\": experience,\n",
    "        \"Projects\": projects\n",
    "    })\n",
    "\n",
    "# Step 5: Export to Excel or CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"taqat_talents.csv\", index=False)\n",
    "\n",
    "print(\"✅ Data scraped and saved to taqat_talents.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae2b551",
   "metadata": {},
   "source": [
    "# This code is for scraping all the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d52cb4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "✅ All pages scraped and saved to taqat_all_talents.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_page(page_num):\n",
    "    url = f\"https://taqat-gaza.com/public/en/talents?page={page_num}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return [], False  # Stop if the page is not accessible\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    cards = soup.find_all(\"div\", class_=\"card\")\n",
    "    if not cards:\n",
    "        return [], False  # Stop if there are no more talents/cards\n",
    "\n",
    "    page_data = []\n",
    "\n",
    "    for card in cards:\n",
    "        name = card.find(\"h5\", class_=\"mb-0\")\n",
    "        specialty = card.find(\"span\", class_=\"text-muted d-block mb-2\")\n",
    "\n",
    "        experience = \"\"\n",
    "        projects = \"\"\n",
    "\n",
    "        stats_blocks = card.find_all(\"div\", class_=\"stats m-1\")\n",
    "        for stat in stats_blocks:\n",
    "            label = stat.find(\"p\")\n",
    "            value = stat.find(\"span\")\n",
    "            if label and value:\n",
    "                label_text = label.get_text(strip=True).lower()\n",
    "                if \"projects\" in label_text:\n",
    "                    projects = value.get_text(strip=True)\n",
    "                elif \"experience\" in label_text:\n",
    "                    experience = value.get_text(strip=True)\n",
    "\n",
    "        page_data.append({\n",
    "            \"Name\": name.text.strip() if name else \"\",\n",
    "            \"Specialty\": specialty.text.strip() if specialty else \"\",\n",
    "            \"Experience (years)\": experience,\n",
    "            \"Projects\": projects\n",
    "        })\n",
    "\n",
    "    return page_data, True\n",
    "\n",
    "# Loop over pages until no more data\n",
    "all_data = []\n",
    "page = 1\n",
    "while True:\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    data, has_more = scrape_page(page)\n",
    "    if not has_more:\n",
    "        break\n",
    "    all_data.extend(data)\n",
    "    page += 1\n",
    "\n",
    "# Export to CSV\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv(\"taqat_all_talents.csv\", index=False)\n",
    "print(\"✅ All pages scraped and saved to taqat_all_talents.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
